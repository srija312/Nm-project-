{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPkLnTmK1BOd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Data Collection\n",
        "path = \"/enhanced_road_safety_dataset.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(\"Dataset loaded with shape:\", df.shape)\n",
        "\n",
        "# 2. Data Cleaning\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle any unrealistic GPS speed values\n",
        "df = df[(df['GPS_Speed_kmph'] >= 0) & (df['GPS_Speed_kmph'] <= 150)]\n",
        "\n",
        "# 3. Exploratory Data Analysis (EDA)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='Accident_Severity', data=df)\n",
        "plt.title(\"Accident Severity Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(x='Accident_Severity', y='GPS_Speed_kmph', data=df)\n",
        "plt.title(\"GPS Speed vs. Accident Severity\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature Engineering\n",
        "# Encode categorical variables\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Select features and target\n",
        "X = df.drop(columns=[\"Accident_ID\", \"Accident_Severity\"])\n",
        "y = df[\"Accident_Severity\"]\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 5. Model Building\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 7. Visualization & Interpretation\n",
        "importances = model.feature_importances_\n",
        "features = df.drop(columns=[\"Accident_ID\", \"Accident_Severity\"]).columns\n",
        "feat_importances = pd.Series(importances, index=features)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Feature Importances\")\n",
        "plt.show()"
      ]
    }
  ]
}